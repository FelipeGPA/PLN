{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FelipeGPA/PLN/blob/main/C%C3%B3pia_de_2023_Q3_PLN_ATIVIDADE_PR%C3%81TICA_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2023.Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **ATIVIDADE PRÁTICA 04 [Uso da API da OpenAI com técnicas de PLN]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "A **ATIVIDADE PRÁTICA 04** deve ser feita utilizando o **Google Colab** com uma conta sua vinculada ao Gmail. O link do seu notebook, armazenado no Google Drive, além do link de um repositório no GitHub e os principais resultados da atividade, devem ser enviados usando o seguinte formulário:\n",
        "\n",
        "> https://forms.gle/GzwCq3R7ExtE9g9a8\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submissão deve ser feita até o dia **26/11 (domingo)** APENAS POR UM INTEGRANTE DA EQUIPE, até às 23h59. Por favor, lembre-se de dar permissão de ACESSO IRRESTRITO para o professor da disciplina de PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA:`\n",
        "Felipe Gonçalves Paulo de Almeida - 11201921612\n",
        "\n",
        "**Integrante 02:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA:`\n",
        " André Luiz Duarte Cesar - 11201922263\n"
      ],
      "metadata": {
        "id": "tnIArN0QY-Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LIVRO**\n",
        "---"
      ],
      "metadata": {
        "id": "6yExhaebs-nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português.`\n",
        "\n",
        ">\n",
        "\n",
        "Disponível gratuitamente em:\n",
        "  \n",
        "  > https://brasileiraspln.com/livro-pln/1a-edicao/.\n",
        "\n",
        "\n",
        "**POR FAVOR, PREENCHER OS CAPITULOS SELECIONADOS PARA A SUA EQUIPE:**\n",
        "\n",
        "`Primeiro capítulo:` https://brasileiraspln.com/livro-pln/1a-edicao/parte6/cap13/cap13.html\n",
        "\n",
        "`Segundo capítulo:` https://brasileiraspln.com/livro-pln/1a-edicao/parte10/cap25/cap25.html\n",
        "\n"
      ],
      "metadata": {
        "id": "DjJM_qhEZRy6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementar um `notebook` no `Google Colab` que faça uso da **API da OpenAI** aplicando, no mínimo, 3 técnicas de PLN. As técnicas devem ser aplicadas nos 2 (DOIS) capítulos do livro **Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português**.\n",
        "\n",
        ">\n",
        "\n",
        "**RESTRIÇÃO**: É obrigatório usar o *endpoint* \"*`Chat Completions`*\".\n",
        "\n",
        ">\n",
        "\n",
        "As seguintes técnicas de PLN podem ser usadas:\n",
        "\n",
        "*   Correção Gramatical\n",
        "*   Classificação de Textos\n",
        "*   Análise de Sentimentos\n",
        "*   Detecção de Emoções\n",
        "*   Extração de Palavras-chave\n",
        "*   Tradução de Textos\n",
        "*   Sumarização de Textos\n",
        "*   **Similaridade de Textos**\n",
        "*   **Reconhecimento de Entidades Nomeadas**\n",
        "*   **Sistemas de Perguntas e Respostas**\n",
        "\n",
        ">\n",
        "\n",
        "Os capítulos devem ser os mesmos selecionados na **ATIVIDADE PRÁTICA 02**. Para consultar os capítulos, considere a seguinte planilha:\n",
        "\n",
        ">\n",
        "\n",
        "> https://docs.google.com/spreadsheets/d/1ZutzQ3v1OJgsgzCvCwxXlRIQ3ChXNlHNvB63JQvYsbo/edit?usp=sharing\n",
        "\n",
        ">\n",
        ">\n",
        "\n",
        "**IMPORTANTE:** É obrigatório usar o e-mail da UFABC. Não é permitido alterar os capítulos já selecionados.\n",
        "\n"
      ],
      "metadata": {
        "id": "fXTwkiiGs2BV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CRITÉRIOS DE AVALIAÇÃO**\n",
        "---\n"
      ],
      "metadata": {
        "id": "gWsBYQNtxmum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Serão considerados como critérios de avaliação as técnicas usadas e a criatividade envolvida na aplicação das mesmas.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5iHdx4BXYruQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPLEMENTAÇÃO**\n",
        "---"
      ],
      "metadata": {
        "id": "nw09lujGvfjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extraindo os capítulos selecionados"
      ],
      "metadata": {
        "id": "kunuZNhH5U3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re"
      ],
      "metadata": {
        "id": "RyUailD5vi9E"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://brasileiraspln.com/livro-pln/1a-edicao/parte6/cap13/cap13.html'\n",
        "\n",
        "# Faz a solicitação HTTP para obter o conteúdo HTML da página do livro\n",
        "response = requests.get(url)\n",
        "\n",
        "# Cria um objeto BeautifulSoup para analisar o conteúdo HTML\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Encontra o elemento HTML que contém o texto do livro\n",
        "book_text = soup.find('main',{'id': 'quarto-document-content'})\n",
        "\n",
        "# Extrai o texto do livro a partir do elemento HTML\n",
        "book = book_text.get_text()"
      ],
      "metadata": {
        "id": "OELuuG0q5mHF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url2 = 'https://brasileiraspln.com/livro-pln/1a-edicao/parte10/cap25/cap25.html'\n",
        "\n",
        "# Faz a solicitação HTTP para obter o conteúdo HTML da página do livro\n",
        "response2 = requests.get(url2)\n",
        "\n",
        "# Cria um objeto BeautifulSoup para analisar o conteúdo HTML\n",
        "soup = BeautifulSoup(response2.content, 'html.parser')\n",
        "\n",
        "# Encontra o elemento HTML que contém o texto do livro\n",
        "book_text2 = soup.find('section', {'id': 'desafios-e-perspectivas-para-o-pln-português'})\n",
        "book_text3 = soup.find('section', {'id': 'há-limites-para-o-pln'})\n",
        "# Extrai o texto do livro a partir do elemento HTML\n",
        "book2 = book_text2.get_text() + book_text3.get_text()"
      ],
      "metadata": {
        "id": "m9yMtZbO5rPa"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(book)\n",
        "print(book2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMzIB7sT5v0_",
        "outputId": "d432705c-8c40-4eb5-cf29-bfdca036787d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "13  Pragmática\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Leidiana Iza Andrade Freitas \n",
            "Vládia Pinheiro \n",
            "\n",
            "\n",
            "\n",
            "Publicado em:\n",
            "\n",
            "26/09/2023\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "PDF\n",
            "O presente capítulo encontra-se em fase de desenvolvimento e será lançado nas próximas edições, portanto, apresentamos um breve resumo. A emergência e a constituição do domínio pragmático são antes de tudo imputáveis a uma situação de crise da filosofia, ocorrida no final do século XIX, em razão da qual as diferentes correntes de pensamento efetuaram um retorno radical à questão da linguagem. Do ponto de vista linguístico, a pragmática é um conjunto de teorias desenvolvidas com a perspectiva de analisar o uso concreto das linguagens naturais considerando a influência do contexto comunicacional, extrapolando assim a visão da semântica e da sintaxe. Dentre as principais teorias destacam-se a Teoria dos Atos de Fala, de Searle, as Teorias do Inferencialismo Semântico, de Sellars, Dummett e Brandom, e o Princípio Cooperativo, de Grice. Este capítulo terá como objetivo explanar tais teorias e filosofias da linguagem e apresentar os frameworks e aplicações de PLN que visam processar textos sob a ótica racional e pragmática das linguagens naturais. Em especial, o capítulo abordará a tarefa de Reconhecimento de Implicação Textual (Recognizing Textual Entailment – RTE) e demais sistemas de Inferência em Linguagem Natural (Natural Language Inference – NLI).\n",
            "\n",
            "\n",
            "25.1 Desafios e perspectivas para o PLN-Português\n",
            "Por razões históricas e econômicas, os sistemas atuais de PLN “estado da arte” são muito mais comuns em inglês do que em qualquer outra língua. Enquanto que outras comunidades têm adaptado para suas línguas os sistemas originalmente criados para o inglês (por meio de novos treinamentos, mas com aproveitamento de parâmetros), comunidades linguísticas minoritárias e comunidades linguísticas de países menos desenvolvidos são invisibilizadas no mundo digital, com consequências negativas e diretas na sua economia e desenvolvimento.\n",
            "Segundo o Instituto Camões, em 2022, a comunidade de falantes de português no mundo era estimada em cerca de 260 milhões de pessoas (3,7% da população mundial) sendo o quarto idioma mais usado, depois do mandarim, inglês e espanhol. Contudo, essa representatividade não é contemplada no estado da arte da ciência, que está majoritariamente nas mãos de instituições e organizações não falantes do português. Pesquisadores brasileiros e portugueses têm levantado a necessidade de unir forças para colocar o português no lugar de destaque que ele merece1.\n",
            "O processamento do português brasileiro tem avançado de maneira consistente desde meados da década de 1990, principalmente a partir do uso de AM e de abordagens cross-language e multilíngue, que facilitam a construção rápida de recursos e soluções, e permitem a geração de uma aplicação em uma língua a partir de uma aplicação em outra língua. Mas ainda é precária a união de esforços entre os países da Comunidade de Países de Língua Portuguesa (CPLP), que inclui Portugal, Angola, Moçambique, Cabo Verde, Guiné-Bissau, São Tomé e Príncipe, além do Brasil. Se as diferenças linguísticas entre os diferentes idiomas representam barreiras para a criação de sistemas comuns, não há dúvida de que a união de esforços trará benefícios para todos. Por ora, o esforço mais visível é aquele entre os mais fortes do grupo, Brasil e Portugal, que realizam um evento científico bianual comum, o PROPOR2, e mantêm vínculos acadêmicos há várias décadas. Dois grandes repositórios de recursos e ferramentas linguístico-computacionais do Português, que pretendem abranger as diversas comunidades de língua portuguesa são a Linguateca3 e o Portulan Clarin4.\n",
            "Em países extensos como o Brasil, onde há uma grande variedade linguística, a exemplo das diferentes línguas indígenas faladas em território nacional5, das variações dialetais e sociais e dos sotaques regionais do português brasileiro, suas riquezas e diversidades linguísticas dificilmente são representadas nos corpora. Essa sub-representação nos dados de treinamento de modelos de aprendizado de máquina é um dos fatores que contribuem para aumentar a codificação de vieses por esses sistemas. Percebe-se, portanto, a importância de os dados linguísticos que alimentam tais sistemas serem coletados de forma responsável, buscando representar as variações linguísticas e idiomáticas das línguas faladas no país.\n",
            "Um dos primeiros corpora em português brasileiro usado para treinar um modelo de língua é o BrWac (Brazilian Portuguese Web as corpus), composto por 3,53 milhões de documentos da web, totalizando 2,68 bilhões de tokens, com acesso público para pesquisadores6. Já o corpus Carolina, do Centro de IA, C4AI7, é, de acordo com os autores, “um corpus com um volume robusto de textos em Português Brasileiro contemporâneo (1970-2021), com informações de procedência e tipologia. O corpus está disponível em acesso aberto, para download gratuito, desde 8 de março de 2022. A versão atual, Ada 1.2 (8 de março de 2023), tem 823 milhões de tokens, mais de dois milhões de textos e mais de 11 GBs”8. Esse corpus é um importante passo para o treinamento de LLM do português brasileiro, e tem o mérito de incluir uma grande variedade de gêneros (jornalismo, literatura, poesia, judiciário, wikis, mídia social, legislativo, acadêmico etc.), mas ainda não contempla as diversidades regionais e culturais dessa língua, meta perseguida pelo C4AI com a construção do corpus de fala (transcrições) TaRSila9, previsto para contemplar os diferentes dialetos brasileiros. Todos esses corpora pretendem ser variados quanto a gênero textual e domínio.\n",
            "No mesmo C4AI, o projeto PROINDL10 promete usar a IA em parceria com comunidades indígenas para o desenvolvimento de ferramentas que promovam a preservação, revitalização e disseminação de línguas indígenas do Brasil. Um dos objetivos é explorar as técnicas que utilizam poucos dados para criar tradutores automáticos tanto para texto como para fala, além de outras aplicações.\n",
            "Mesmo com a limitação de variedade e tamanho de corpora em português para treinamento de LLMs, grandes modelos de língua para o português já são encontrados, quer sejam modelos com capacidade multilíngue (ex. os modelos PALM da Google), quer sejam treinados apenas em português (ex. BERTimbau(Souza; Nogueira; Lotufo, 2020), Sabiá (Pires et al., 2023), Albertina11). Dessa forma, são claros os avanços em direção a produtos para a língua portuguesa. No entanto, o que pode parecer simples (corpus + redes neurais e Transformers + fine-tuning = LLM) pode ser, de fato, inviável. O custo de se produzir um LLM de qualidade é extremamente alto. Um ótimo LLM, como o LLaMA-65B, por exemplo, foi pré-treinado com 1.4 trilhão de palavras, em 40 mil GPU12-horas, consumindo energia equivalente ao consumo de cerca de 10 casas brasileiras em um ano13.\n",
            "De um lado, são necessárias muitas GPUs para treinar modelos competitivos: quanto maior o número de GPUs, mais parâmetros podem ser usados no modelo, aumentando sua eficácia numa tarefa. Atualmente, poucas instituições públicas ou privadas dispõem de infraestrutura para tal e, ainda assim, com número de GPUs bastante inferior (de 2 a 100) àquela disponível em nuvem (clusters de TPUs14) com preços de aluguel que podem chegar a um milhão de dólares. Pesquisadores costumam recorrer a recursos gratuitos e temporários oferecidos pelas gigantes internacionais (ex. Google Cloud). Essa dependência externa por recursos essenciais ao desenvolvimento tecnológico só pode ser minimizada por meio de ações e investimentos governamentais (p.ex. centralizados pelo CNPq) ou por iniciativas coletivas dos detentores de recursos no sentido de juntá-los para incrementar o poder computacional e compartilhá-lo com toda a comunidade. De outro lado, independentemente do fator financeiro, temos o custo energético, com efeito na emissão de carbono, que, como vimos, não é desprezível.\n",
            "Essas questões nos fazem refletir sobre os próximos caminhos a seguir. Nem tudo se resolve com grandes modelos de língua, assim como há muitas aplicações interessantes que podem ser desenvolvidas ou com modelos mais modestos ou por meios distintos dos modelos de língua. Considerando tarefas e domínios de conhecimento particulares, é possível construir soluções a partir de modelos treinados apenas nesse domínio. De fato, os resultados tendem a ser melhores do que com o uso de modelos mais genéricos. Além disso, considerar uma tarefa mais específica pode levar a uma solução - qualquer que seja a abordagem - mais eficaz.\n",
            "As limitações para a academia não impedem, no entanto, que o PLN seja cada vez mais usado por empresas e startups da área, cujo número vem crescendo muito em nosso país. Certamente isso é fruto da alta demanda por sistemas dessa natureza, mas também do investimento das universidades públicas na formação de recursos humanos nessa área. Estamos vivendo um momento de grande absorção dos profissionais de PLN pelo mercado. Mais um motivo para refletirmos sobre a formação desses profissionais frente aos grandes desafios que essa área (e a IA de modo geral) nos coloca.\n",
            "Além de todas as questões levantadas anteriormente, vale ressaltar a relevância de se adequar os critérios de avaliação tradicionalmente usados para sistemas de IA e, em particular, de PLN, à nova realidade das aplicações oferecidas à sociedade. A cultura acadêmica sugere uma avaliação em cenários rigidamente controlados, usando apenas métricas objetivas (numéricas), visando quase que exclusivamente a comparação com outros sistemas. Assim é a ciência e assim ela evolui. No entanto, tendo em vista o alcance que as novas tecnologias têm na sociedade, é urgente que os métodos de avaliação considerem critérios de outras naturezas, critérios que ajudem a prever o comportamento do sistema em situações, de fato, reais, sabidamente complexas, onde a imprevisibilidade é um fator relevante.\n",
            "\n",
            "25.2 Há limites para o PLN?\n",
            "A língua é frequentemente citada como sinal de inteligência e, por isso, nos distinguiria de outros animais. É por essa razão, aliás, que o PLN sempre esteve ligado à área de Inteligência Artificial. Sistemas dotados de habilidades linguísticas estariam entre os (artificialmente) inteligentes. No entanto, inteligência é algo difícil de se definir. Apenas parecer inteligente nos faz inteligentes? Essa questão sempre esteve presente na IA. Como definir um sistema inteligente? É necessário que ele raciocine como os humanos (seja bioinspirado), que tenha conhecimento explicitamente representado em seus algoritmos, ou basta que suas respostas sejam similares às de um humano nas mesmas situações? Não há acordo sobre isso, até porque sequer conseguimos concordar com os critérios de classificação de inteligência humana.\n",
            "No caso do PLN, isso se traduz na seguinte questão: aos sistemas que mostram habilidade linguística pode-se atribuir inteligência? Ainda: eles de fato dominam o conhecimento total sobre a língua e todos os fenômenos que a língua em uso nos apresenta?\n",
            "A língua tem sido objeto de estudo, análise e fascínio nas mais variadas áreas do conhecimento: filosofia, literatura, linguística, psicologia, psicanálise, ciências cognitivas, comunicação social, entre outras, e, recentemente, do PLN. Isso revela que a língua é um objeto de estudo bastante rico e complexo, e, portanto, não é possível abordá-lo segundo uma única disciplina.\n",
            "O PLN tem sido apresentado como uma área comum a duas disciplinas, Computação e Linguística. No passado, isso parecia suficiente, pois apenas a porção formal, estrutural da língua era tratada computacionalmente15. Com o passar do tempo, a evolução das máquinas e as redes sociais, isso mudou. Essa língua em uso no cenário digital atual só pode ser tratada de forma transdisciplinar. Não é um caminho simples, nem cômodo, nem garantidor de que o PLN terá sucesso. Pelo contrário, não é improvável que, ao tratar a língua em toda sua complexidade, concluamos que há um limite para o PLN que independe de avanços tecnológicos.\n",
            "Os capítulos anteriores evidenciam que PLN é uma área de grande potencial, porém repleta de desafios, sobre os quais é difícil fazer previsões. Várias tarefas de IA têm sido solucionadas pelas tecnologias atuais (Redes Neurais, Aprendizado de Máquina) que não são ideias novas; elas ficaram adormecidas até que o hardware das máquinas pudesse processá-las eficientemente. Em se tratando de PLN, no entanto, não é razoável prever que avanços de hardware, ou mesmo de métodos, garantam a solução completa para todos os sistemas que envolvem a língua. A demanda por sistemas que processam a língua não para de crescer. Vale notar que demandas e métodos são interdependentes: enquanto as demandas provocam novos métodos, estes últimos abrem caminho para novas demandas antes não possíveis.\n",
            "Este livro também evidenciou que o desempenho linguístico dos sistemas atuais de PLN espelham aquilo que aprendem a partir dos dados de treinamento dos algoritmos de aprendizado: língua na norma culta, língua mal formada, discursos de ódio, misoginia ou racismo; o que quer que tenha sido oferecido ao algoritmo de aprendizado a título de exemplo eventualmente será reproduzido pelo sistema gerado. Como o conhecimento (a língua) adquirido nesses sistemas não é explicitamente representado (ele está imerso em valores probabilísticos ou parâmetros numéricos das redes neurais), não há um controle de quando e como ele será usado. Todos esses efeitos colaterais dessa tecnologia preocupam a sociedade e trazem para a comunidade de PLN desafios e responsabilidades não existentes antes. As trajetórias da IA e do PLN têm nos ensinado que o alcance de metas mais modestas e realistas, ao longo do tempo, tem nos levado a patamares cada vez mais surpreendentes.\n",
            "Convidamos você a esperar para ver, ou fazer para acontecer.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "PIRES, R. et al. Sabiá: Portuguese Large Language Models. Anais da XII Brazilian Conference on Intelligent Systems - BRACIS 2023. Anais...2023. Disponível em: <https://arxiv.org/abs/2304.07880>\n",
            "\n",
            "\n",
            "SOUZA, F.; NOGUEIRA, R.; LOTUFO, R. BERTimbau: pretrained BERT models for Brazilian Portuguese. (R. Cerri, R. C. Prati, Eds.)Proceedings of the 2020 Brazilian Conference on Intelligent Systems. Anais...Springer International Publishing, 2020.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INSTALANDO OS PACOTES NECESSÁRIOS**"
      ],
      "metadata": {
        "id": "vAfXCIhw6yo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP2vHXqk6ZcL",
        "outputId": "de78ea78-4f84-46bc-8335-def620deac4a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.3.5-py3-none-any.whl (220 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/220.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/220.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.8/220.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUhXYghN6fLw",
        "outputId": "eba5ace3-3db9-46dc-8d45-51bf3a5827fe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: openai\n",
            "Version: 1.3.5\n",
            "Summary: The official Python library for the openai API\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: OpenAI <support@openai.com>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: anyio, distro, httpx, pydantic, tqdm, typing-extensions\n",
            "Required-by: llmx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ2G5Wxm6oEP",
        "outputId": "59fc8ac1-23ce-4d6c-ffae-47e94ea6ad89"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Validando instalações e modelos\n",
        "import requests\n",
        "import json\n",
        "\n",
        "headers = {\"Authorization\" : f\"Bearer {openai.api_key}\"}\n",
        "link = \"https://api.openai.com/v1/models\"\n",
        "requisicao = requests.get(link, headers=headers)\n",
        "print(requisicao)\n",
        "print(requisicao.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJzg6tuiAFR6",
        "outputId": "91810d11-c9db-42ea-dd01-a5e2d3b722aa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n",
            "{\n",
            "  \"object\": \"list\",\n",
            "  \"data\": [\n",
            "    {\n",
            "      \"id\": \"text-search-babbage-doc-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172509,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-3.5-turbo-16k\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1683758102,\n",
            "      \"owned_by\": \"openai-internal\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"curie-search-query\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172509,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-davinci-003\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1669599635,\n",
            "      \"owned_by\": \"openai-internal\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-search-babbage-query-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172509,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"babbage\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1649358449,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"babbage-search-query\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172509,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-babbage-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1649364043,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-similarity-davinci-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172505,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-3.5-turbo-1106\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1698959748,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"davinci-similarity\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172509,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"code-davinci-edit-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1649880484,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"curie-similarity\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172510,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"babbage-search-document\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172510,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"curie-instruct-beta\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1649364042,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-search-ada-doc-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172507,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"davinci-instruct-beta\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1649364042,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-3.5-turbo-instruct\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1692901427,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-similarity-babbage-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172505,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-search-davinci-doc-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172505,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-3.5-turbo-instruct-0914\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1694122472,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"babbage-similarity\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172505,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-embedding-ada-002\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1671217299,\n",
            "      \"owned_by\": \"openai-internal\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"davinci-search-query\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172505,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-similarity-curie-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172507,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-davinci-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1649364042,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-search-davinci-query-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172505,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"ada-search-document\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172507,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"ada-code-search-code\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172505,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"babbage-002\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1692634615,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"davinci-002\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1692634301,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"davinci-search-document\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172509,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"curie-search-document\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172508,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"babbage-code-search-code\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172509,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-search-ada-query-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172505,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"code-search-ada-text-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172507,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-3.5-turbo-16k-0613\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1685474247,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"babbage-code-search-text\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172509,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"code-search-babbage-code-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172507,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"ada-search-query\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172505,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"ada-code-search-text\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172510,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"tts-1-hd\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1699046015,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-search-curie-query-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172509,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-davinci-002\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1649880484,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-davinci-edit-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1649809179,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"code-search-babbage-text-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172507,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"tts-1-hd-1106\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1699053533,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"ada\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1649357491,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-ada-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1649364042,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"ada-similarity\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172507,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"code-search-ada-code-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172507,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-similarity-ada-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172505,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"canary-whisper\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1699656801,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"whisper-1\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1677532384,\n",
            "      \"owned_by\": \"openai-internal\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-search-curie-doc-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1651172509,\n",
            "      \"owned_by\": \"openai-dev\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"text-curie-001\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1649364043,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"curie\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1649359874,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"canary-tts\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1699492935,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"tts-1\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1681940951,\n",
            "      \"owned_by\": \"openai-internal\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-3.5-turbo-0613\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1686587434,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-3.5-turbo-0301\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1677649963,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"gpt-3.5-turbo\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1677610602,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"davinci\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1649359874,\n",
            "      \"owned_by\": \"openai\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"dall-e-2\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1698798177,\n",
            "      \"owned_by\": \"system\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"tts-1-1106\",\n",
            "      \"object\": \"model\",\n",
            "      \"created\": 1699053241,\n",
            "      \"owned_by\": \"system\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**API_KEY**"
      ],
      "metadata": {
        "id": "YwNbVlJp7Tjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from google.colab import files\n",
        "\n",
        "upload_arquivo = files.upload()\n",
        "\n",
        "senha = list(upload_arquivo.keys())[0]\n",
        "\n",
        "with open(senha, 'r') as file:\n",
        "   API_KEY = file.read()\n",
        "\n",
        "openai.api_key = API_KEY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "4PkJbxJp6opw",
        "outputId": "2c553b5c-c054-42ec-9624-e3aa7b3e7f19"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8c8b64e4-1678-46c3-9170-87e00ae78186\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8c8b64e4-1678-46c3-9170-87e00ae78186\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving API_KEY_openai.txt to API_KEY_openai (2).txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"gpt-3.5-turbo-16k\"         #Selecionando o modelo que usaremos"
      ],
      "metadata": {
        "id": "ecrFoxGY8ZxI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "headers = {\"Authorization\" : f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
        "link1 = \"https://api.openai.com/v1/chat/completions\"\n",
        "\n"
      ],
      "metadata": {
        "id": "WLcKfO8a81cY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CORREÇÃO GRAMATICAL**"
      ],
      "metadata": {
        "id": "BdHGWoLC_ceP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"Dado o texto em seguida encontre erros gramaticais, liste-os e corrija os mesmos. \\n\\nTexto: {book}\"\n",
        "body_msg = {\n",
        "    \"model\": model,\n",
        "    \"messages\": [\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "      }]\n",
        "}\n",
        "body_msg = json.dumps(body_msg)\n",
        "\n",
        "requisicao5 = requests.post(link1, headers=headers, data=body_msg)\n",
        "resposta = requisicao5.json()\n",
        "mensagem = resposta[\"choices\"][0][\"message\"][\"content\"]\n",
        "print(mensagem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdnN9CGq-7RB",
        "outputId": "6dffa9d0-6597-476e-a549-ff5d3f34829b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erros gramaticais identificados no texto:\n",
            "\n",
            "1. Falta de espaçamento após o número \"13\"\n",
            "2. O nome \"Leidiana Iza Andrade Freitas\" está separado por uma linha em branco, indicando que deveria estar em uma nova linha\n",
            "3. A palavra \"Vládia\" está separada por uma linha em branco, indicando que deveria estar em uma nova linha\n",
            "4. O título \"Publicado em:\" está escrito em maiúsculas, quando deveria estar em minúsculas\n",
            "5. Falta de espaçamento após o título \"Publicado em:\"\n",
            "6. O texto menciona \"nas próximas edições\", indicando que o capítulo ainda não foi lançado, mas em seguida afirma que \"apresentamos um breve resumo\", indicando que já foi apresentado. Isso cria uma contradição na informação.\n",
            "7. O trecho \"as diferentes correntes de pensamento efetuaram um retorno radical à questão da linguagem\" está utilizando o pretérito perfeito do indicativo (\"efetuaram\") de forma inadequada, pois se refere a uma situação que ocorreu no passado e tem relação com o presente (a constituição do domínio pragmático).\n",
            "8. O trecho \"desenvolvidas com a perspectiva de analisar o uso concreto das linguagens naturais considerando a influência do contexto comunicacional\" está utilizando o gerúndio (\"considerando\") de forma inadequada, pois deveria utilizar o infinitivo (\"considerar\").\n",
            "9. A palavra \"extrapolando\" está escrita de forma errada, deveria ser \"extrapolando\"\n",
            "10. A frase \"Dentre as principais teorias destacam-se a Teoria dos Atos de Fala, de Searle, as Teorias do Inferencialismo Semântico, de Sellars, Dummett e Brandom, e o Princípio Cooperativo, de Grice\" está utilizando uma estrutura de enumeração inconsistente, pois utiliza o verbo \"destacam-se\" somente na primeira frase e depois apresenta as teorias sem utilizar o verbo.\n",
            "11. A palavra \"explanar\" está escrita de forma errada, deveria ser \"explicar\"\n",
            "12. Os acrônimos \"RTE\" e \"NLI\" não estão explicados, o que pode gerar confusão no leitor\n",
            "\n",
            "Correções realizadas:\n",
            "\n",
            "13. Adicionado espaçamento após o número \"13\"\n",
            "14. O nome \"Leidiana Iza Andrade Freitas\" foi movido para uma nova linha\n",
            "15. A palavra \"Vládia\" foi movida para uma nova linha\n",
            "16. O título \"Publicado em:\" foi corrigido para \"Publicado em\"\n",
            "17. Adicionado espaçamento após o título \"Publicado em\"\n",
            "18. Removida a contradição na informação sobre o lançamento do capítulo\n",
            "19. Alterado o verbo \"efetuaram\" para \"efetuam\" para estar de acordo com a situação descrita\n",
            "20. Alterado o gerúndio \"considerando\" para \"considerar\"\n",
            "21. Corrigida a palavra \"extrapolando\"\n",
            "22. Adicionado verbo \"destacam-se\" antes de cada teoria mencionada na enumeração\n",
            "23. Corrigida a palavra \"explicar\"\n",
            "24. Adicionada explicação para os acrônimos \"RTE\" e \"NLI\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXTRAÇÃO DE PALAVRAS-CHAVES**"
      ],
      "metadata": {
        "id": "WIQNpqCh-xx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"Extraia e liste as palavras-chave dos textos 1 e 2.\\n\\nTexto 1: {book} \\n\\n Texto 2: {book2}\"\"\"\n",
        "body_msg1 = {\n",
        "    \"model\": model,\n",
        "    \"messages\": [\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "      }]\n",
        "}\n",
        "body_msg1 = json.dumps(body_msg1)\n",
        "\n",
        "requisicao4 = requests.post(link1, headers=headers, data=body_msg1)\n",
        "resposta1 = requisicao4.json()\n",
        "mensagem1 = resposta1[\"choices\"][0][\"message\"][\"content\"]\n",
        "print(mensagem1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SW74rup9JW5",
        "outputId": "c8573abe-1bcc-41c9-b45d-a82915b772c4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palavras-chave do Texto 1:\n",
            "- Pragmática\n",
            "- filosofia\n",
            "- linguagem\n",
            "- linguística\n",
            "- semântica\n",
            "- sintaxe\n",
            "- teorias\n",
            "- atos de fala\n",
            "- inferencialismo semântico\n",
            "- princípio cooperativo\n",
            "- Reconhecimento de Implicação Textual\n",
            "- Inferência em Linguagem Natural\n",
            "\n",
            "Palavras-chave do Texto 2:\n",
            "- PLN\n",
            "- desenvolvimento\n",
            "- língua portuguesa\n",
            "- sistemas\n",
            "- comunidade\n",
            "- recursos\n",
            "- diversidades linguísticas\n",
            "- corpora\n",
            "- modelos de aprendizado de máquina\n",
            "- IA\n",
            "- critérios de avaliação\n",
            "- inteligência artificial\n",
            "- desafios\n",
            "- responsabilidades\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SIMILARIDADES DOS TEXTOS**"
      ],
      "metadata": {
        "id": "27Hlu8SkEQaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"Compare o texto 1 com o texto 2 e me dê um percentual de similaridade.\\n\\n Texto 1: {book}. \\n\\n Texto 2: {book2}\"\"\"\n",
        "body_msg1 = {\n",
        "    \"model\": model,\n",
        "    \"messages\": [\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt,\n",
        "      }]\n",
        "}\n",
        "body_msg1 = json.dumps(body_msg1)\n",
        "\n",
        "requisicao4 = requests.post(link1, headers=headers, data=body_msg1)\n",
        "resposta2 = requisicao4.json()\n",
        "mensagem1 = resposta2[\"choices\"][0][\"message\"][\"content\"]\n",
        "print(mensagem1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-tg3amd_i1E",
        "outputId": "27563840-8a44-46fd-c072-6a473b00b644"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Não é possível fornecer um percentual de similaridade entre os textos 1 e 2, pois eles abordam assuntos diferentes. O texto 1 fala sobre a pragmática da linguagem e suas teorias, enquanto o texto 2 discute os desafios e perspectivas do Processamento de Linguagem Natural (PLN) para o idioma português.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRADUÇÃO DE LOCUTORES**"
      ],
      "metadata": {
        "id": "n0kY2Lp9IDvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"Traduza o texto abaixo, como se fosse um criança falando.\\n\\nTexto 1: {book}\"\n",
        "body_msg = {\n",
        "    \"model\": model,\n",
        "    \"messages\": [\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "      }]\n",
        "}\n",
        "body_msg = json.dumps(body_msg)\n",
        "\n",
        "requisicao6 = requests.post(link1, headers=headers, data=body_msg)\n",
        "resposta2 = requisicao6.json()\n",
        "mensagem2 = resposta2[\"choices\"][0][\"message\"][\"content\"]\n",
        "print(mensagem2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prYiDCym_kdQ",
        "outputId": "d9e1b329-1be7-4cd9-8b0d-c462841357e3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto 1:\n",
            "\n",
            "Oi! O capítulo que vamos falar agora é sobre uma coisa muito importante chamada pragmática. É um nome meio difícil, né? Mas é sobre como a gente usa a linguagem de verdade, sabe? Aconteceu uma crise na filosofia lá no passado, e aí as pessoas começaram a pensar muito sobre a linguagem. A pragmática é um conjunto de teorias que analisam como a gente usa a linguagem de verdade, levando em conta o contexto em que a gente fala, isso é super importante. Tem várias teorias famosas, como a Teoria dos Atos de Fala, a Teoria do Inferencialismo Semântico e o Princípio Cooperativo. Nesse capítulo, a gente também vai falar sobre umas coisinhas legais, como Reconhecimento de Implicação Textual e Inferência em Linguagem Natural. É muito interessante!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[PLUS] MUDANÇA DE ESTRUTURA TEXTUAL**"
      ],
      "metadata": {
        "id": "LGEsItCjJISR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"Reescreva o texto em formato de poema clássico.\\n\\n Texto: {book2}\"\n",
        "body_msg = {\n",
        "    \"model\": model,\n",
        "    \"messages\": [\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "      }]\n",
        "}\n",
        "body_msg = json.dumps(body_msg)\n",
        "\n",
        "requisicao = requests.post(link1, headers=headers, data=body_msg)\n",
        "resposta = requisicao.json()\n",
        "mensagem = resposta[\"choices\"][0][\"message\"][\"content\"]\n",
        "print(mensagem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoYtMS8XIc_N",
        "outputId": "557c10fb-3a56-4410-abca-ab0b2bc0e2c4"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25.1 Desafios e perspectivas para o PLN-Português\n",
            "\n",
            "Por razões históricas e econômicas,\n",
            "Os sistemas atuais de PLN \"estado da arte\"\n",
            "São mais encontrados em inglês,\n",
            "Enquanto outras línguas são deixadas para trás.\n",
            "\n",
            "Comunidades minoritárias e de países menos desenvolvidos,\n",
            "São invisíveis no mundo digital, em desvantagem,\n",
            "Afetando negativamente sua economia e desenvolvimento,\n",
            "Um problema que precisa ser encarado com coragem.\n",
            "\n",
            "Segundo o Instituto Camões,\n",
            "O português é falado por 260 milhões de pessoas,\n",
            "Sendo o quarto idioma mais usado no mundo,\n",
            "Mas não recebe a atenção que merece.\n",
            "\n",
            "Os pesquisadores brasileiros e portugueses,\n",
            "Clamam por uma união de forças,\n",
            "Para colocar o português em destaque,\n",
            "E promover seu avanço em todas as áreas.\n",
            "\n",
            "O processamento do português brasileiro,\n",
            "Tem avançado ao longo dos anos,\n",
            "Mas a união entre os países da CPLP é necessária,\n",
            "Para superar as barreiras linguísticas sem temores.\n",
            "\n",
            "Em países como o Brasil, com sua diversidade,\n",
            "As línguas indígenas e os sotaques regionais,\n",
            "Precisam ser representados nos sistemas e corpora,\n",
            "Para evitar vieses e desigualdades sociais.\n",
            "\n",
            "Há corpora disponíveis para treinamento,\n",
            "Como o BrWac e o corpus Carolina,\n",
            "Mas ainda falta representatividade,\n",
            "Das diversidades regionais brasileiras, tão divina.\n",
            "\n",
            "O projeto PROINDL promete usar a IA,\n",
            "Em parceria com comunidades indígenas,\n",
            "Para preservar e disseminar suas línguas,\n",
            "Uma iniciativa que merece nossas salvas.\n",
            "\n",
            "Apesar das limitações e desafios enfrentados,\n",
            "O PLN é cada vez mais utilizado por empresas,\n",
            "Com uma demanda em constante crescimento,\n",
            "E profissionais preparados que não são escassos.\n",
            "\n",
            "É importante refletir sobre os caminhos a seguir,\n",
            "E adequar os critérios de avaliação,\n",
            "Considerando a nova realidade das aplicações,\n",
            "E seus impactos na sociedade, sem hesitação.\n",
            "\n",
            "25.2 Há limites para o PLN?\n",
            "\n",
            "A língua sempre foi sinônimo de inteligência,\n",
            "E o PLN busca explorar esse dom,\n",
            "Mas o que define a inteligência?\n",
            "Não há consenso, é um dilema nenhum.\n",
            "\n",
            "O PLN tem desafios a enfrentar,\n",
            "A língua é complexa em sua essência,\n",
            "Apenas a porção formal não é suficiente,\n",
            "É preciso uma abordagem com mais abrangência.\n",
            "\n",
            "O PLN envolve Computação e Linguística,\n",
            "Mas é preciso uma visão transdisciplinar,\n",
            "Pois a língua em uso atualmente,\n",
            "Não se limita a uma única área.\n",
            "\n",
            "Não é possível prever avanços tecnológicos,\n",
            "No campo do PLN, há um limite,\n",
            "Demandas e métodos são interdependentes,\n",
            "E novas demandas surgirão, isso é um rito.\n",
            "\n",
            "Os sistemas de PLN refletem o que foi aprendido,\n",
            "A partir dos exemplos do treinamento,\n",
            "Mas não há controle total,\n",
            "E isso preocupa a sociedade, é um lamento.\n",
            "\n",
            "Concluímos que metas modestas e realistas,\n",
            "Ao longo do tempo nos surpreendem,\n",
            "O PLN é uma área de grande potencial,\n",
            "Mas é importante refletir, para onde nos remetem.\n"
          ]
        }
      ]
    }
  ]
}